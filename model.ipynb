{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf \n",
    "import tensorflow_io as tfio\n",
    "\n",
    "from datetime import datetime\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Conv2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization, Flatten, LSTM, TimeDistributed\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./RespiratorySoundDatabase/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/\n"
     ]
    }
   ],
   "source": [
    "mypath = './RespiratorySoundDatabase/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/'\n",
    "filenames = [f for f in listdir(mypath) if (isfile(join(mypath, f)) and f.endswith('.wav'))] \n",
    "print(mypath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_id_in_file = [] # patient IDs corresponding to each file\n",
    "for name in filenames:\n",
    "    p_id_in_file.append(int(name[:3]))\n",
    "\n",
    "p_id_in_file = np.array(p_id_in_file)\n",
    "# print(p_id_in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.64041199e+02, -4.18290039e+02, -3.87566589e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 8.44875793e+01,  1.36891495e+02,  1.71178497e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 6.75648041e+01,  8.99741745e+01,  1.04197815e+02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [-2.82355607e-01,  2.05963564e+00,  1.22030616e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-6.52661860e-01,  1.89648938e+00,  5.53389192e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [-6.38449073e-01,  7.99845815e-01, -1.81964302e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_pad_len = 862 # to make the length of all MFCC equal\n",
    "\n",
    "def extract_features(file_name):\n",
    "    \"\"\"\n",
    "    This function takes in the path for an audio file as a string, loads it, and returns the MFCC\n",
    "    of the audio\"\"\"\n",
    "   \n",
    "    try:\n",
    "        audio, sample_rate = librosa.load(file_name, duration=20) \n",
    "        mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=40)\n",
    "    \n",
    "        pad_width = max_pad_len - mfccs.shape[1]\n",
    "        mfccs = np.pad(mfccs, pad_width=((0, 0), (0, pad_width)), mode='constant')\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"Error encountered while parsing file: \", file_name)\n",
    "        return None \n",
    "    return mfccs\n",
    "\n",
    "extract_features(rf'RespiratorySoundDatabase\\Respiratory_Sound_Database\\Respiratory_Sound_Database\\audio_and_txt_files\\104_1b1_Ll_sc_Litt3200.wav')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepaths = [join(mypath, f) for f in filenames] # full paths of files\n",
    "\n",
    "# for f in filepaths:\n",
    "#     print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0          1\n",
      "0    101       URTI\n",
      "1    102    Healthy\n",
      "2    103       COPD\n",
      "3    104       COPD\n",
      "4    105       URTI\n",
      "..   ...        ...\n",
      "121  222       COPD\n",
      "122  223       COPD\n",
      "123  224    Healthy\n",
      "124  225    Healthy\n",
      "125  226  Pneumonia\n",
      "\n",
      "[126 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "p_diag = pd.read_csv(\"./RespiratorySoundDatabase/Respiratory_Sound_Database/Respiratory_Sound_Database/patient_diagnosis.csv\",header=None) # patient diagnosis file\n",
    "print(p_diag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "920\n"
     ]
    }
   ],
   "source": [
    "# labels = np.array([p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]) # labels for audio files\n",
    "\n",
    "labels = [p_diag[p_diag[0] == x][1].values[0] for x in p_id_in_file]\n",
    "print(type(labels))\n",
    "print(len(labels))\n",
    "# print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished feature extraction from  920  files\n"
     ]
    }
   ],
   "source": [
    "from soundfile import SoundFile\n",
    "features = []\n",
    "idx = 0 \n",
    "# Iterate through each sound file and extract the features\n",
    "for file_name in filepaths:\n",
    "    with SoundFile(file_name, 'r') as file_name:\n",
    "        data = extract_features(file_name)\n",
    "        features.append(data)\n",
    "\n",
    "print('Finished feature extraction from ', len(features), ' files')\n",
    "# features = np.array(features,dtype=object).flatten() \n",
    "# for i in features:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "920\n"
     ]
    }
   ],
   "source": [
    "print(len(features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "<class 'list'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "X = features\n",
    "y = labels\n",
    "print(type(X))\n",
    "print(type(y))\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736\n",
      "736\n",
      "184\n",
      "184\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(X_test))\n",
    "print(len(y_test))\n",
    "print(len(X_train[0]))\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# One-hot encode the training labels\n",
    "y_train = to_categorical(y_train)\n",
    "# print(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 40\n",
    "num_columns = 862\n",
    "num_channels = 1\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, kernel_size=5, strides=1, padding='same', input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(6, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_39 (Conv2D)          (None, 40, 862, 64)       1664      \n",
      "                                                                 \n",
      " batch_normalization_38 (Bat  (None, 40, 862, 64)      256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_38 (MaxPoolin  (None, 20, 431, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_40 (Conv2D)          (None, 20, 431, 128)      204928    \n",
      "                                                                 \n",
      " batch_normalization_39 (Bat  (None, 20, 431, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_39 (MaxPoolin  (None, 10, 215, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 10, 215, 128)      0         \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 275200)            0         \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 256)               70451456  \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 512)               131584    \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 70,793,478\n",
      "Trainable params: 70,793,094\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "23/23 [==============================] - 58s 2s/step - loss: 57.8647 - accuracy: 0.6630 - val_loss: 115.1548 - val_accuracy: 0.8152\n",
      "Epoch 2/10\n",
      "23/23 [==============================] - 55s 2s/step - loss: 9.2784 - accuracy: 0.7867 - val_loss: 46.1118 - val_accuracy: 0.1685\n",
      "Epoch 3/10\n",
      "23/23 [==============================] - 56s 2s/step - loss: 1.9915 - accuracy: 0.8207 - val_loss: 13.4288 - val_accuracy: 0.7609\n",
      "Epoch 4/10\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.7870 - accuracy: 0.8397 - val_loss: 6.8191 - val_accuracy: 0.7283\n",
      "Epoch 5/10\n",
      "23/23 [==============================] - 56s 2s/step - loss: 0.4607 - accuracy: 0.8777 - val_loss: 3.1067 - val_accuracy: 0.7554\n",
      "Epoch 6/10\n",
      "23/23 [==============================] - 56s 2s/step - loss: 0.5041 - accuracy: 0.8750 - val_loss: 3.5673 - val_accuracy: 0.7989\n",
      "Epoch 7/10\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.4075 - accuracy: 0.8764 - val_loss: 2.5712 - val_accuracy: 0.8098\n",
      "Epoch 8/10\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.4336 - accuracy: 0.8750 - val_loss: 0.8555 - val_accuracy: 0.7935\n",
      "Epoch 9/10\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.4753 - accuracy: 0.8764 - val_loss: 0.7614 - val_accuracy: 0.8098\n",
      "Epoch 10/10\n",
      "23/23 [==============================] - 57s 2s/step - loss: 0.4616 - accuracy: 0.8791 - val_loss: 0.6234 - val_accuracy: 0.8152\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19c4b076cb0>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=10, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 10s 444ms/step - loss: 0.4561 - accuracy: 0.8818\n",
      "Training Accuracy:  0.8817934989929199\n",
      "6/6 [==============================] - 3s 417ms/step - loss: 0.6234 - accuracy: 0.8152\n",
      "Testing Accuracy:  0.8152173757553101\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model on the training and testing set\n",
    "score = model.evaluate(X_train, y_train)\n",
    "print(\"Training Accuracy: \", score[1])\n",
    "\n",
    "score = model.evaluate(X_test, y_test)\n",
    "print(\"Testing Accuracy: \", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 40, 862, 1)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('my_model.h5')\n",
    "\n",
    "# Load the input data\n",
    "input_data = extract_features('./RespiratorySoundDatabase/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/104_1b1_Ll_sc_Litt3200.wav')\n",
    "\n",
    "\n",
    "input_data = input_data.reshape(1, 40, 862, 1)\n",
    "print(input_data.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Bronchiectasis' 'Bronchiolitis' 'COPD' 'Healthy' 'Pneumonia' 'URTI']\n",
      "./RespiratorySoundDatabase/Respiratory_Sound_Database/Respiratory_Sound_Database/audio_and_txt_files/102_1b1_Ar_sc_Meditron.wav\n",
      "Healthy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "lbls = np.unique(labels)\n",
    "print(lbls)\n",
    "print(filepaths[2])\n",
    "print(labels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 69ms/step\n",
      "[0.01439044 0.03732305 0.6423005  0.09150169 0.13805687 0.07642743]\n",
      "COPD\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "# Print the predictions\n",
    "predictions = predictions.reshape(6)\n",
    "print(predictions)\n",
    "mx = predictions[0]\n",
    "index = 0 \n",
    "for i in predictions:\n",
    "    if i > mx :\n",
    "        mx = i \n",
    "# print(mx)\n",
    "indices = np.where(predictions == mx)\n",
    "\n",
    "# Print the indices\n",
    "# print(indices)\n",
    "\n",
    "# Create the dictionary\n",
    "dictionary = dict(zip(lbls, predictions))\n",
    "\n",
    "# print(dictionary)\n",
    "max_element = max(dictionary,key=dictionary.get)\n",
    "print(max_element)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
